{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8245488,"sourceType":"datasetVersion","datasetId":4891846},{"sourceId":8255378,"sourceType":"datasetVersion","datasetId":4899019}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport pandas as pd\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nimport copy\nfrom torch.utils.data import Dataset, DataLoader\nimport gc\nimport random\nimport wandb\nimport csv\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom matplotlib.font_manager import FontProperties","metadata":{"_cell_guid":"f4ce1158-c562-476f-8f7d-0325f0b787c4","_uuid":"549ce73a-e98b-42bd-a1d8-2cab5faae7d5","collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T08:50:29.804904Z","iopub.execute_input":"2025-05-20T08:50:29.805198Z","iopub.status.idle":"2025-05-20T08:50:37.599865Z","shell.execute_reply.started":"2025-05-20T08:50:29.805176Z","shell.execute_reply":"2025-05-20T08:50:37.599280Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"wandb.login(key=\"986fd96a25245251243e3084fc375526692b03b6\")","metadata":{"execution":{"iopub.status.busy":"2025-05-20T08:50:41.241775Z","iopub.execute_input":"2025-05-20T08:50:41.242658Z","iopub.status.idle":"2025-05-20T08:50:47.714960Z","shell.execute_reply.started":"2025-05-20T08:50:41.242632Z","shell.execute_reply":"2025-05-20T08:50:47.714306Z"},"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhamu2908\u001b[0m (\u001b[33mm_dhamu2908\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Checking if CUDA is available, else use CPU\nprint(device)  # Printing the device being used (CUDA or CPU)\nEND_TOKEN = '>'  # Defining the end token for sequences\nSTART_TOKEN = '<'  # Defining the start token for sequences\nPAD_TOKEN = '_'  # Defining the padding token for sequences\nTEACHER_FORCING_RATIO = 0.5  # Ratio of teacher forcing during training\n\n# Paths to the train, test, and validation CSV files\ntrain_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_train.csv\"\ntest_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_test.csv\"\nval_csv = \"/kaggle/input/aksh11/aksharantar_sampled/tel/tel_valid.csv\"\n\n# Reading the train, test, and validation CSV files into pandas dataframes\ntrain_df = pd.read_csv(train_csv, header=None)\ntest_df = pd.read_csv(test_csv, header=None)\nval_df = pd.read_csv(val_csv, header=None)\n\n# Extracting source and target sequences from train, test, and validation dataframes\ntrain_source, train_target = train_df[0].to_numpy(), train_df[1].to_numpy()\nval_source, val_target = val_df[0].to_numpy(), val_df[1].to_numpy()\ntest_source, test_target = test_df[0].to_numpy(), test_df[1].to_numpy()","metadata":{"_cell_guid":"c7dcb64a-f20a-4fa2-8b31-9801c3a762b8","_uuid":"b6363452-eb4f-4705-aa3f-fdec65f8e9db","collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T08:51:02.373322Z","iopub.execute_input":"2025-05-20T08:51:02.373790Z","iopub.status.idle":"2025-05-20T08:51:02.610716Z","shell.execute_reply.started":"2025-05-20T08:51:02.373767Z","shell.execute_reply":"2025-05-20T08:51:02.610079Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Function to add padding to source sequences\ndef add_padding(source_data, MAX_LENGTH):\n    \"\"\"\n    Add padding to source sequences and truncate if necessary.\n    \n    Args:\n    - source_data: List of source sequences\n    - MAX_LENGTH: Maximum length of source sequences\n    \n    Returns:\n    - padded_source_strings: List of padded source sequences\n    \"\"\"\n    padded_source_strings = []\n    for i in range(len(source_data)):\n        source_str = START_TOKEN + source_data[i] + END_TOKEN  # Add start and end tokens\n        source_str = source_str[:MAX_LENGTH]  # Truncate if longer than MAX_LENGTH\n        source_str += PAD_TOKEN * (MAX_LENGTH - len(source_str))  # Pad with PAD_TOKEN\n\n        padded_source_strings.append(source_str)\n        \n    return padded_source_strings\n\n\n# Function to convert source strings to sequences of indices\ndef generate_string_to_sequence(source_data, source_char_index_dict):\n    \"\"\"\n    Convert source strings to sequences of indices using char_index_dict.\n    \n    Args:\n    - source_data: List of padded source strings\n    - source_char_index_dict: Dictionary mapping characters to their indices\n    \n    Returns:\n    - source_sequences: Padded sequence of character indices\n    \"\"\"\n    source_sequences = []\n    for i in range(len(source_data)):\n        source_sequences.append(get_chars(source_data[i], source_char_index_dict))\n    source_sequences = pad_sequence(source_sequences, batch_first=True, padding_value=2)\n    return source_sequences\n\n\n# Function to convert characters to their corresponding indices\ndef get_chars(string, char_index_dict):\n    \"\"\"\n    Convert characters in a string to their corresponding indices using char_index_dict.\n    \n    Args:\n    - string: Input string\n    - char_index_dict: Dictionary mapping characters to their indices\n    \n    Returns:\n    - chars_indexes: List of character indices\n    \"\"\"\n    chars_indexes = []\n    for char in string:\n        chars_indexes.append(char_index_dict[char])\n    return torch.tensor(chars_indexes, device=device)\n\n\n# Preprocess the data, including adding padding, generating sequences, and updating dictionaries\ndef preprocess_data(source_data, target_data):\n    \"\"\"\n    Preprocess source and target data.\n    \n    Args:\n    - source_data: List of source strings\n    - target_data: List of target strings\n    \n    Returns:\n    - data: Preprocessed data dictionary\n    \"\"\"\n    data = {\n        \"source_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"target_chars\": [START_TOKEN, END_TOKEN, PAD_TOKEN],\n        \"source_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"source_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"target_char_index\": {START_TOKEN: 0, END_TOKEN: 1, PAD_TOKEN: 2},\n        \"target_index_char\": {0: START_TOKEN, 1: END_TOKEN, 2: PAD_TOKEN},\n        \"source_len\": 3,\n        \"target_len\": 3,\n        \"source_data\": source_data,\n        \"target_data\": target_data,\n        \"source_data_seq\": [],\n        \"target_data_seq\": []\n    }\n    \n    # Calculate the maximum length of input and output sequences\n    data[\"INPUT_MAX_LENGTH\"] = max(len(string) for string in source_data) + 2\n    data[\"OUTPUT_MAX_LENGTH\"] = max(len(string) for string in target_data) + 2\n\n    # Pad the source and target sequences and update character dictionaries\n    padded_source_strings = add_padding(source_data, data[\"INPUT_MAX_LENGTH\"])\n    padded_target_strings = add_padding(target_data, data[\"OUTPUT_MAX_LENGTH\"])\n    \n    for i in range(len(padded_source_strings)):\n        for char in padded_source_strings[i]:\n            if data[\"source_char_index\"].get(char) is None:\n                data[\"source_chars\"].append(char)\n                idx = len(data[\"source_chars\"]) - 1\n                data[\"source_char_index\"][char] = idx\n                data[\"source_index_char\"][idx] = char\n        for char in padded_target_strings[i]:\n            if data[\"target_char_index\"].get(char) is None:\n                data[\"target_chars\"].append(char)\n                idx = len(data[\"target_chars\"]) - 1\n                data[\"target_char_index\"][char] = idx\n                data[\"target_index_char\"][idx] = char\n\n    # Generate sequences of indexes for source and target data\n    data['source_data_seq'] = generate_string_to_sequence(padded_source_strings, data['source_char_index'])\n    data['target_data_seq'] = generate_string_to_sequence(padded_target_strings, data['target_char_index'])\n    \n    # Update lengths of source and target character lists\n    data[\"source_len\"] = len(data[\"source_chars\"])\n    data[\"target_len\"] = len(data[\"target_chars\"])\n    \n    return data\n","metadata":{"_cell_guid":"fb22b602-e1fc-496b-93dc-f4d3178870d5","_uuid":"3708abf3-c2df-4e8d-8cfe-af3faab7bc53","collapsed":false,"execution":{"iopub.status.busy":"2025-05-20T08:51:06.412744Z","iopub.execute_input":"2025-05-20T08:51:06.413432Z","iopub.status.idle":"2025-05-20T08:51:06.425490Z","shell.execute_reply.started":"2025-05-20T08:51:06.413406Z","shell.execute_reply":"2025-05-20T08:51:06.424534Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_cell_type(cell_type):\n    # Function to return the appropriate RNN cell based on the specified type\n    if(cell_type == \"RNN\"):\n        return nn.RNN\n    elif(cell_type == \"LSTM\"):\n        return nn.LSTM\n    elif(cell_type == \"GRU\"):\n        return nn.GRU\n    else:\n        print(\"Specify correct cell type\")\n\nclass Attention(nn.Module):\n    def __init__(self, hidden_size):\n        # Initialize the attention mechanism module\n        super(Attention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        # Forward pass of the attention mechanism\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze().unsqueeze(1)\n        weights = F.softmax(scores, dim=0)\n        weights = weights.permute(2,1,0)\n        keys = keys.permute(1,0,2)\n        context = torch.bmm(weights, keys)\n        return context, weights\n\nclass Encoder(nn.Module):\n    def __init__(self, h_params, data, device ):\n        # Initialize the Encoder module\n        super(Encoder, self).__init__()\n        # Embedding layer for input characters\n        self.embedding = nn.Embedding(data[\"source_len\"], h_params[\"char_embd_dim\"])\n        # RNN cell for encoding\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],num_layers=h_params[\"number_of_layers\"], batch_first=True)\n        self.device=device\n        self.h_params = h_params\n        self.data = data\n        \n    def forward(self, input , encoder_curr_state):\n        # Forward pass of the Encoder module\n        input_length = self.data[\"INPUT_MAX_LENGTH\"]\n        batch_size = self.h_params[\"batch_size\"]\n        hidden_neurons = self.h_params[\"hidden_layer_neurons\"]\n        layers = self.h_params[\"number_of_layers\"]\n        encoder_states  = torch.zeros(input_length, layers, batch_size, hidden_neurons, device=self.device )\n        for i in range(input_length):\n            current_input = input[:, i].view(batch_size,1)\n            _, encoder_curr_state = self.forward_step(current_input, encoder_curr_state)\n            if self.h_params[\"cell_type\"] == \"LSTM\":\n                encoder_states[i] = encoder_curr_state[1]\n            else:\n                encoder_states[i] = encoder_curr_state\n        return encoder_states, encoder_curr_state\n    \n    def forward_step(self, current_input, prev_state):\n        # Perform forward pass for one time step\n        embd_input = self.embedding(current_input)\n        output, prev_state = self.cell(embd_input, prev_state)\n        return output, prev_state\n        \n    def getInitialState(self):\n        # Initialize initial hidden state for encoder\n        return torch.zeros(self.h_params[\"number_of_layers\"],self.h_params[\"batch_size\"],self.h_params[\"hidden_layer_neurons\"], device=self.device)\n\nclass Decoder(nn.Module):\n    def __init__(self, h_params, data,device):\n        # Initialize the Decoder module\n        super(Decoder, self).__init__()\n        # Attention mechanism\n        self.attention = Attention(h_params[\"hidden_layer_neurons\"]).to(device)\n        # Embedding layer for target characters\n        self.embedding = nn.Embedding(data[\"target_len\"], h_params[\"char_embd_dim\"])\n        # RNN cell for decoding\n        self.cell = get_cell_type(h_params[\"cell_type\"])(h_params[\"hidden_layer_neurons\"] +h_params[\"char_embd_dim\"], h_params[\"hidden_layer_neurons\"],num_layers=h_params[\"number_of_layers\"], batch_first=True)\n        # Fully connected layer for output\n        self.fc = nn.Linear(h_params[\"hidden_layer_neurons\"], data[\"target_len\"])\n        # Softmax activation for output probabilities\n        self.softmax = nn.LogSoftmax(dim=2)\n        self.h_params = h_params\n        self.data = data\n        self.device = device\n\n    def forward(self, decoder_current_state, encoder_final_layers, target_batch, loss_fn, teacher_forcing_enabled=True):\n        # Forward pass of the Decoder module\n        batch_size = self.h_params[\"batch_size\"]\n        decoder_current_input = torch.full((batch_size,1),self.data[\"target_char_index\"][START_TOKEN], device=self.device)\n        embd_input = self.embedding(decoder_current_input)\n        curr_embd = F.relu(embd_input)\n        decoder_actual_output = []\n        attentions = []\n        loss = 0\n        \n        use_teacher_forcing = False\n        if(teacher_forcing_enabled):\n            use_teacher_forcing = True if random.random() < TEACHER_FORCING_RATIO else False\n        for i in range(self.data[\"OUTPUT_MAX_LENGTH\"]):\n            # Perform one step of decoding\n            decoder_output, decoder_current_state, attn_weights = self.forward_step(decoder_current_input, decoder_current_state, encoder_final_layers)\n            attentions.append(attn_weights)\n            topv, topi = decoder_output.topk(1)\n            decoder_current_input = topi.squeeze().detach()\n            decoder_actual_output.append(decoder_current_input)\n\n            if(target_batch==None):\n                decoder_current_input = decoder_current_input.view(self.h_params[\"batch_size\"], 1)\n            else:\n                curr_target_chars = target_batch[:, i]\n                if(i<self.data[\"OUTPUT_MAX_LENGTH\"]-1):\n                    if use_teacher_forcing:\n                        decoder_current_input = target_batch[:, i+1].view(self.h_params[\"batch_size\"], 1)\n                    else:\n                        decoder_current_input = decoder_current_input.view(self.h_params[\"batch_size\"], 1)\n                decoder_output = decoder_output[:, -1, :]\n                loss+=(loss_fn(decoder_output, curr_target_chars))\n\n        decoder_actual_output = torch.cat(decoder_actual_output,dim=0).view(self.data[\"OUTPUT_MAX_LENGTH\"], self.h_params[\"batch_size\"]).transpose(0,1)\n\n        correct = (decoder_actual_output == target_batch).all(dim=1).sum().item()\n        return decoder_actual_output, attentions, loss, correct\n    \n    def forward_step(self, current_input, prev_state, encoder_final_layers):\n        # Perform one step of decoding\n        embd_input = self.embedding(current_input)\n        if self.h_params[\"cell_type\"] == \"LSTM\":\n            context , attn_weights = self.attention(prev_state[1][-1,:,:], encoder_final_layers)\n        else:\n            context , attn_weights = self.attention(prev_state[-1,:,:], encoder_final_layers)\n        curr_embd = F.relu(embd_input)\n        input_gru = torch.cat((curr_embd, context), dim=2)\n        output, prev_state = self.cell(input_gru, prev_state)\n        output = self.softmax(self.fc(output))\n        return output, prev_state, attn_weights\n","metadata":{"_cell_guid":"52035e98-753c-4cd0-8dec-2cec35aab863","_uuid":"58e2b696-e336-4cb3-b6e6-d14eac238c96","execution":{"iopub.status.busy":"2025-05-20T08:51:10.906678Z","iopub.execute_input":"2025-05-20T08:51:10.907421Z","iopub.status.idle":"2025-05-20T08:51:10.925399Z","shell.execute_reply.started":"2025-05-20T08:51:10.907397Z","shell.execute_reply":"2025-05-20T08:51:10.924516Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, data):\n        self.source_data_seq = data[0]\n        self.target_data_seq = data[1]\n    \n    def __len__(self):\n        return len(self.source_data_seq)\n    \n    def __getitem__(self, idx):\n        source_data = self.source_data_seq[idx]\n        target_data = self.target_data_seq[idx]\n        return source_data, target_data\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T08:51:15.097238Z","iopub.execute_input":"2025-05-20T08:51:15.098027Z","iopub.status.idle":"2025-05-20T08:51:15.102711Z","shell.execute_reply.started":"2025-05-20T08:51:15.098001Z","shell.execute_reply":"2025-05-20T08:51:15.101771Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def evaluate(encoder, decoder, data, dataloader, device, h_params, loss_fn, use_teacher_forcing = False):\n    # Function to evaluate the performance of the model on a dataset\n    correct_predictions = 0\n    total_loss = 0\n    total_predictions = len(dataloader.dataset)\n    number_of_batches = len(dataloader)\n    encoder.eval()\n    decoder.eval()\n    \n    with torch.no_grad():\n        for batch_num, (source_batch, target_batch) in enumerate(dataloader):\n\n            encoder_initial_state = encoder.getInitialState()\n            if h_params[\"cell_type\"] == \"LSTM\":\n                encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n            encoder_states, encoder_final_state = encoder(source_batch,encoder_initial_state)\n\n            decoder_current_state = encoder_final_state\n            encoder_final_layer_states = encoder_states[:, -1, :, :]\n\n            loss = 0\n            correct = 0\n\n            decoder_output, attentions, loss, correct = decoder(decoder_current_state, encoder_final_layer_states, target_batch, loss_fn, use_teacher_forcing)\n\n            correct_predictions+=correct\n            total_loss +=loss\n\n        accuracy = correct_predictions / total_predictions\n        total_loss /= number_of_batches\n\n        return accuracy, total_loss\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T08:51:28.351554Z","iopub.execute_input":"2025-05-20T08:51:28.352078Z","iopub.status.idle":"2025-05-20T08:51:28.357873Z","shell.execute_reply.started":"2025-05-20T08:51:28.352053Z","shell.execute_reply":"2025-05-20T08:51:28.357031Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def make_strings(data, source, target, output):\n    # Function to convert indices to strings for source, target, and output sequences\n    source_string = \"\"\n    target_string = \"\"\n    output_string = \"\"\n    for i in source:\n        source_string+=(data['source_index_char'][i.item()])\n    for i in target:\n        target_string+=(data['target_index_char'][i.item()])\n    for i in output:\n        output_string+=(data['target_index_char'][i.item()])\n    return source_string, target_string, output_string\n\n\ndef train_loop(encoder, decoder,h_params, data, data_loader, device, val_dataloader, use_teacher_forcing=True):\n    # Function to train the encoder-decoder model\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=h_params[\"learning_rate\"])\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=h_params[\"learning_rate\"])\n    \n    loss_fn = nn.NLLLoss()\n    \n    total_predictions = len(data_loader.dataset)\n    total_batches = len(data_loader)\n    \n    for ep in range(h_params[\"epochs\"]):\n        total_correct = 0\n        total_loss = 0\n        encoder.train()\n        decoder.train()\n        for batch_num, (source_batch, target_batch) in enumerate(data_loader):\n            encoder_initial_state = encoder.getInitialState()\n            \n            if h_params[\"cell_type\"] == \"LSTM\":\n                encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n            encoder_states, encoder_final_state = encoder(source_batch,encoder_initial_state)\n            \n            decoder_current_state = encoder_final_state\n            encoder_final_layer_states = encoder_states[:, -1, :, :]\n            \n            \n            loss = 0\n            correct = 0\n            \n            decoder_output, attentions, loss, correct = decoder(decoder_current_state, encoder_final_layer_states, target_batch, loss_fn, use_teacher_forcing)\n            total_correct +=correct\n            total_loss += loss.item()/data[\"OUTPUT_MAX_LENGTH\"]\n            \n            encoder_optimizer.zero_grad()\n            decoder_optimizer.zero_grad()\n            loss.backward()\n            encoder_optimizer.step()\n            decoder_optimizer.step()\n            \n            \n        train_acc = total_correct/total_predictions\n        train_loss = total_loss/total_batches\n        val_acc, val_loss = evaluate(encoder, decoder, data, val_dataloader,device, h_params, loss_fn, False)\n        print(\"ep: \", ep, \" train acc:\", train_acc, \" train loss:\", train_loss, \" val acc:\", val_acc, \" val loss:\", val_loss.item()/data[\"OUTPUT_MAX_LENGTH\"])\n        wandb.log({\"train_accuracy\":train_acc, \"train_loss\":train_loss, \"val_accuracy\":val_acc, \"val_loss\":val_loss, \"epoch\":ep})\n    return loss_fn","metadata":{"_cell_guid":"0dc20b89-db7b-4230-a7ec-e76d1896adee","_uuid":"c743c5b1-1106-4388-a594-e4e301225bad","execution":{"iopub.status.busy":"2025-05-20T08:51:41.296665Z","iopub.execute_input":"2025-05-20T08:51:41.297156Z","iopub.status.idle":"2025-05-20T08:51:41.305774Z","shell.execute_reply.started":"2025-05-20T08:51:41.297131Z","shell.execute_reply":"2025-05-20T08:51:41.305146Z"},"scrolled":true,"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"h_params={\n    \"char_embd_dim\" : 256,  \n    \"hidden_layer_neurons\": 512,  \n    \"batch_size\": 64, \n    \"number_of_layers\": 3,  \n    \"learning_rate\": 0.0001,  \n    \"epochs\": 20, \n    \"cell_type\": \"LSTM\", \n    \"dropout\": 0, \n    \"optimizer\": \"adam\" \n}\n\ndef prepare_dataloaders(train_source, train_target, val_source, val_target,test_source, test_target, h_params):\n    # Preparing data loaders for training and validation\n    data = preprocess_data(copy.copy(train_source), copy.copy(train_target))\n    \n    # Training data\n    training_data = [data[\"source_data_seq\"], data['target_data_seq']]\n    train_dataset = MyDataset(training_data)\n    train_dataloader = DataLoader(train_dataset, batch_size=h_params[\"batch_size\"], shuffle=False)\n\n    # Validation data\n    val_padded_source_strings = add_padding(val_source, data[\"INPUT_MAX_LENGTH\"])\n    val_padded_target_strings = add_padding(val_target, data[\"OUTPUT_MAX_LENGTH\"])\n    val_source_sequences = generate_string_to_sequence(val_padded_source_strings, data['source_char_index'])\n    val_target_sequences = generate_string_to_sequence(val_padded_target_strings, data['target_char_index'])\n    validation_data = [val_source_sequences, val_target_sequences]\n    val_dataset = MyDataset(validation_data)\n    val_dataloader = DataLoader(val_dataset, batch_size=h_params[\"batch_size\"], shuffle=False)\n    \n    # test data\n    test_padded_source_strings = add_padding(test_source, data[\"INPUT_MAX_LENGTH\"])\n    test_padded_target_strings = add_padding(test_target, data[\"OUTPUT_MAX_LENGTH\"])\n    test_source_sequences = generate_string_to_sequence(test_padded_source_strings, data['source_char_index'])\n    test_target_sequences = generate_string_to_sequence(test_padded_target_strings, data['target_char_index'])\n    test_data = [test_source_sequences, test_target_sequences]\n    test_dataset = MyDataset(test_data)\n    test_dataloader = DataLoader(test_dataset, batch_size=h_params[\"batch_size\"], shuffle=False)\n    \n    return train_dataloader, val_dataloader, test_dataloader, data\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T08:51:50.322081Z","iopub.execute_input":"2025-05-20T08:51:50.322825Z","iopub.status.idle":"2025-05-20T08:51:50.330184Z","shell.execute_reply.started":"2025-05-20T08:51:50.322802Z","shell.execute_reply":"2025-05-20T08:51:50.329484Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def train(h_params, data, device, data_loader, val_dataloader, use_teacher_forcing=True):\n    encoder = Encoder(h_params, data, device).to(device)\n    decoder = Decoder(h_params, data, device).to(device)\n    loss_fn = train_loop(encoder, decoder,h_params, data, data_loader,device, val_dataloader, use_teacher_forcing)\n    return encoder, decoder, loss_fn","metadata":{"execution":{"iopub.status.busy":"2025-05-20T08:51:57.986867Z","iopub.execute_input":"2025-05-20T08:51:57.987417Z","iopub.status.idle":"2025-05-20T08:51:57.991656Z","shell.execute_reply.started":"2025-05-20T08:51:57.987395Z","shell.execute_reply":"2025-05-20T08:51:57.990940Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#It will print the test accura\nacc, loss = evaluate(encoder,decoder, data, test_dataloader, device, config, loss_fn)\nprint(acc, loss/data[\"OUTPUT_MAX_LENGTH\"])\ndef remove_padding(str):\n    padding_removed_string = \"\"\n    for ch in str:\n        if ch ==\"<\" or ch == \">\" or ch ==\"_\":\n            continue\n        padding_removed_string+=ch\n    return padding_removed_string\n\n\n#It will generate the attention heatmap\ndef plot_attention_heatmap(attention_matrix, input_sequence, output_sequence , id):\n\n    plt.figure(figsize=(15, 10))\n\n    ax = sns.heatmap(attention_matrix, cmap='viridis', annot=False, xticklabels=input_sequence, yticklabels=output_sequence)\n\n    # Set font properties for Telugu characters\n    font_path = '/kaggle/input/fonts-bro-1/NotoSansTelugu-VariableFont_wdth,wght.ttf'  # Replace with the path to a Telugu font file\n    telugu_font = FontProperties(fname=font_path)\n\n    ax.set_xticklabels(input_sequence, fontproperties=telugu_font)\n    ax.set_yticklabels(output_sequence, fontproperties=telugu_font)\n\n    ax.set_xlabel('Input Sequence')\n    ax.set_ylabel('Output Sequence')\n    plt.title('Attention Heatmap')\n    wandb.log({\"Attention_Heatmap\"+str(id)+ \"temp\": wandb.Image(plt)})\n\n    plt.close()\n#     plt.show()\n\ndef generate_predictions_report(encoder, decoder, data, dataloader, device, config, loss_fn):\n    encoder.eval()\n    decoder.eval()\n    \n    zeroth_batch_attention = \"\"\n    zeroth_source_batch = \"\"\n    zeroth_target_batch = \"\"\n    \n    # The CSV file will be saved in the current working directory\n    with open('predictions_report.csv', mode='w', newline='') as file:\n        writer = csv.writer(file)\n        writer.writerow(['Source String', 'Target String', 'Predicted String'])\n        \n        with torch.no_grad():\n            for batch_num, (source_batch, target_batch) in enumerate(dataloader):\n\n                encoder_initial_state = encoder.getInitialState()\n                if config[\"cell_type\"] == \"LSTM\":\n                    encoder_initial_state = (encoder_initial_state, encoder.getInitialState())\n                encoder_states, encoder_final_state = encoder(source_batch, encoder_initial_state)\n\n                decoder_current_state = encoder_final_state\n                encoder_final_layer_states = encoder_states[:, -1, :, :]\n\n                # Generate decoder output\n                decoder_output, attentions, loss, correct = decoder(decoder_current_state, encoder_final_layer_states, target_batch, loss_fn, False)\n                if batch_num == 0:\n                    zeroth_batch_attention = attentions\n                    zeroth_source_batch = source_batch\n                    zeroth_target_batch = target_batch\n\n                # Generate the list of true and predicted words\n                for j in range(config[\"batch_size\"]):\n                    src_str, target_str, pred_str = make_strings(data, source_batch[j], target_batch[j], decoder_output[j])\n                    writer.writerow([remove_padding(src_str), remove_padding(target_str), remove_padding(pred_str)])\n\n            \n            processed_atten = torch.zeros(config[\"batch_size\"], data[\"OUTPUT_MAX_LENGTH\"], data[\"INPUT_MAX_LENGTH\"])\n            \n            for i in range(data[\"OUTPUT_MAX_LENGTH\"]):\n                temp = zeroth_batch_attention[i][:, 0, :]\n                for j in range(config[\"batch_size\"]):\n                    processed_atten[j][i] = temp[j]\n               \n            for i in range(10):\n                curr_src_seq = zeroth_source_batch[i]\n                curr_trg_seq = zeroth_target_batch[i]\n                curr_src_seq = [data[\"source_index_char\"][k.item()] for k in curr_src_seq]\n                curr_trg_seq = [data[\"target_index_char\"][k.item()] for k in curr_trg_seq]\n                plot_attention_heatmap(processed_atten[i], curr_src_seq, curr_trg_seq, i)\n\n\ngenerate_predictions_report(encoder, decoder, data, test_dataloader, device, config, loss_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T08:52:03.984008Z","iopub.execute_input":"2025-05-20T08:52:03.984310Z","iopub.status.idle":"2025-05-20T08:52:04.069063Z","shell.execute_reply.started":"2025-05-20T08:52:03.984284Z","shell.execute_reply":"2025-05-20T08:52:04.068110Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1566944145.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#It will print the test accura\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"OUTPUT_MAX_LENGTH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpadding_removed_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"],"ename":"NameError","evalue":"name 'encoder' is not defined","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Run this cell to run a sweep with appropriate parameters\nsweep_params = {\n    'method' : 'bayes',\n    'name'   : 'DL Assignment 3 With Attention',\n    'metric' : {\n        'goal' : 'maximize',\n        'name' : 'val_accuracy',\n    },\n    'parameters' : {\n        'epochs':{'values' : [15, 20]},\n        'learning_rate':{'values' : [0.001, 0.0001]},\n        'batch_size':{'values':[32,64, 128]},\n        'char_embd_dim':{'values' : [64, 128, 256] } ,\n        'number_of_layers':{'values' : [1,2,3,4]},\n        'optimizer':{'values':['nadam','adam']},\n        'cell_type':{'values' : [\"RNN\",\"LSTM\", \"GRU\"]},\n        'hidden_layer_neurons':{'values': [ 128, 256, 512]},\n        'dropout':{'values': [0,0.2, 0.3]}\n    }\n}\n\nsweep_id = wandb.sweep(sweep=sweep_params, project=\"Deep_Learning_Assignment3a\")\ndef main():\n    wandb.init(project=\"Deep_Learning_Assignment3a\" )\n    config = wandb.config\n    with wandb.init(project=\"Deep_Learning_Assignment3a\", name=f\"{config['cell_type']}_{config['optimizer']}_ep_{config['epochs']}_lr_{config['learning_rate']}_embd_{config['char_embd_dim']}_hid_lyr_neur_{config['hidden_layer_neurons']}_bs_{config['batch_size']}_enc_layers_{config['number_of_layers']}_dec_layers_{config['number_of_layers']}_dropout_{config['dropout']}\", config=config):\n        train_dataloader, val_dataloader,test_dataloader, data = prepare_dataloaders(train_source, train_target, val_source, val_target,test_source, test_target, config)\n        train(config, data, device, train_dataloader, val_dataloader, True)","metadata":{"execution":{"iopub.status.busy":"2025-05-20T08:52:46.391773Z","iopub.execute_input":"2025-05-20T08:52:46.392565Z","iopub.status.idle":"2025-05-20T08:52:46.785084Z","shell.execute_reply.started":"2025-05-20T08:52:46.392538Z","shell.execute_reply":"2025-05-20T08:52:46.784213Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Create sweep with ID: n15yi8bx\nSweep URL: https://wandb.ai/m_dhamu2908/Deep_Learning_Assignment3a/sweeps/n15yi8bx\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"wandb.agent(\"n15yi8bx\", function=main, count=100)","metadata":{"execution":{"execution_failed":"2025-05-20T15:42:35.315Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"config = h_params\nrun = wandb.init(project=\"Deep_Learning_Assignment3a\", name=f\"{config['cell_type']}_{config['optimizer']}_ep_{config['epochs']}_lr_{config['learning_rate']}_embd_{config['char_embd_dim']}_hid_lyr_neur_{config['hidden_layer_neurons']}_bs_{config['batch_size']}_enc_layers_{config['number_of_layers']}_dec_layers_{config['number_of_layers']}_dropout_{config['dropout']}\", config=config)\ntrain_dataloader, val_dataloader, test_dataloader, data = prepare_dataloaders(train_source, train_target, val_source, val_target,test_source, test_target, h_params)\nencoder, decoder, loss_fn = train(h_params, data, device, train_dataloader, val_dataloader, True)","metadata":{"execution":{"iopub.execute_input":"2024-05-17T09:23:55.756306Z","iopub.status.busy":"2024-05-17T09:23:55.756051Z","iopub.status.idle":"2024-05-17T10:08:43.505090Z","shell.execute_reply":"2024-05-17T10:08:43.504125Z","shell.execute_reply.started":"2024-05-17T09:23:55.756284Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjaswanth431\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.17.0 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240517_092355-wcpu2ayh</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/jaswanth431/DL%20Assignment%203%20With%20Attention%201/runs/wcpu2ayh' target=\"_blank\">LSTM_adam_ep_20_lr_0.0001_embd_128_hid_lyr_neur_512_bs_32_enc_layers_2_dec_layers_2_dropout_0.3</a></strong> to <a href='https://wandb.ai/jaswanth431/DL%20Assignment%203%20With%20Attention%201' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/jaswanth431/DL%20Assignment%203%20With%20Attention%201' target=\"_blank\">https://wandb.ai/jaswanth431/DL%20Assignment%203%20With%20Attention%201</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/jaswanth431/DL%20Assignment%203%20With%20Attention%201/runs/wcpu2ayh' target=\"_blank\">https://wandb.ai/jaswanth431/DL%20Assignment%203%20With%20Attention%201/runs/wcpu2ayh</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ep:  0  train acc: 0.05705078125  train loss: 1.3567165669150976  val acc: 0.0  val loss: 1.2356311963952107\n","ep:  1  train acc: 0.35916015625  train loss: 0.7328936720931022  val acc: 0.0068359375  val loss: 0.7459257374639097\n","ep:  2  train acc: 0.4886328125  train loss: 0.38329930001343426  val acc: 0.13232421875  val loss: 0.47324748661207117\n","ep:  3  train acc: 0.567421875  train loss: 0.25723866042559584  val acc: 0.307373046875  val loss: 0.3494106790293818\n","ep:  4  train acc: 0.64888671875  train loss: 0.19122661505066532  val acc: 0.353759765625  val loss: 0.3150609057882558\n","ep:  5  train acc: 0.68744140625  train loss: 0.16484403335261558  val acc: 0.38818359375  val loss: 0.2963656342547873\n","ep:  6  train acc: 0.70115234375  train loss: 0.14890617834454717  val acc: 0.403076171875  val loss: 0.2789236358974291\n","ep:  7  train acc: 0.715703125  train loss: 0.13896221505174322  val acc: 0.408447265625  val loss: 0.2738995137421981\n","ep:  8  train acc: 0.73595703125  train loss: 0.12299607858712207  val acc: 0.43017578125  val loss: 0.27457954572594684\n","ep:  9  train acc: 0.74412109375  train loss: 0.12037767865519168  val acc: 0.449462890625  val loss: 0.26554543039073114\n","ep:  10  train acc: 0.7511328125  train loss: 0.11277949936900544  val acc: 0.448974609375  val loss: 0.2549426659293797\n","ep:  11  train acc: 0.7616796875  train loss: 0.10254337787306766  val acc: 0.4638671875  val loss: 0.25737246223117993\n","ep:  12  train acc: 0.76779296875  train loss: 0.10004147787742906  val acc: 0.475830078125  val loss: 0.2575191000233526\n","ep:  13  train acc: 0.778359375  train loss: 0.09201607343242185  val acc: 0.466064453125  val loss: 0.2568577683490256\n","ep:  14  train acc: 0.77900390625  train loss: 0.08957105845020594  val acc: 0.454833984375  val loss: 0.25938734800919244\n","ep:  15  train acc: 0.77806640625  train loss: 0.08956836237738523  val acc: 0.473876953125  val loss: 0.2565872772880223\n","ep:  16  train acc: 0.7964453125  train loss: 0.07919978042988547  val acc: 0.458740234375  val loss: 0.2585204787876295\n","ep:  17  train acc: 0.797109375  train loss: 0.0763582599002224  val acc: 0.4775390625  val loss: 0.255900590316109\n","ep:  18  train acc: 0.80662109375  train loss: 0.07065794031421074  val acc: 0.4814453125  val loss: 0.25241233991539996\n","ep:  19  train acc: 0.80123046875  train loss: 0.07048481421329396  val acc: 0.49267578125  val loss: 0.2584547167238982\n"]}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}